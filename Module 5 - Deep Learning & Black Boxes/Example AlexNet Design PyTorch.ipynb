{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":7702,"status":"ok","timestamp":1698621275349,"user":{"displayName":"Daniel Vasiliu","userId":"13280890113502714012"},"user_tz":240},"id":"fXeduiPZtzDL"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from torchvision import datasets\n","from torchvision import transforms\n","from torch.utils.data.sampler import SubsetRandomSampler"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1698621275350,"user":{"displayName":"Daniel Vasiliu","userId":"13280890113502714012"},"user_tz":240},"id":"Ize-U5XGtzDO"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cuda device\n"]}],"source":["# Get gpu, mps or cpu device for training.\n","device = (\n","    \"cuda\"\n","    if torch.cuda.is_available()\n","    else \"mps\"\n","    if torch.backends.mps.is_available()\n","    else \"cpu\"\n",")\n","print(f\"Using {device} device\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11430,"status":"ok","timestamp":1698621286777,"user":{"displayName":"Daniel Vasiliu","userId":"13280890113502714012"},"user_tz":240},"id":"DcSjYje2tzDO","outputId":"ca3ece28-6294-49fe-a035-ee4b5773ae02"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 170498071/170498071 [00:15<00:00, 10785915.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["def get_train_valid_loader(data_dir,\n","                           batch_size,\n","                           augment,\n","                           random_seed,\n","                           valid_size=0.1,\n","                           shuffle=True):\n","    normalize = transforms.Normalize(\n","        mean=[0.4914, 0.4822, 0.4465],\n","        std=[0.2023, 0.1994, 0.2010],\n","    )\n","\n","    # define transforms\n","    valid_transform = transforms.Compose([\n","            transforms.Resize((227,227)),\n","            transforms.ToTensor(),\n","            normalize,\n","    ])\n","    if augment:\n","        train_transform = transforms.Compose([\n","            transforms.RandomCrop(32, padding=4),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.ToTensor(),\n","            normalize,\n","        ])\n","    else:\n","        train_transform = transforms.Compose([\n","            transforms.Resize((227,227)),\n","            transforms.ToTensor(),\n","            normalize,\n","        ])\n","\n","    # load the dataset\n","    train_dataset = datasets.CIFAR10(\n","        root=data_dir, train=True,\n","        download=True, transform=train_transform,\n","    )\n","\n","    valid_dataset = datasets.CIFAR10(\n","        root=data_dir, train=True,\n","        download=True, transform=valid_transform,\n","    )\n","\n","    num_train = len(train_dataset)\n","    indices = list(range(num_train))\n","    split = int(np.floor(valid_size * num_train))\n","\n","    if shuffle:\n","        np.random.seed(random_seed)\n","        np.random.shuffle(indices)\n","\n","    train_idx, valid_idx = indices[split:], indices[:split]\n","    train_sampler = SubsetRandomSampler(train_idx)\n","    valid_sampler = SubsetRandomSampler(valid_idx)\n","\n","    train_loader = torch.utils.data.DataLoader(\n","        train_dataset, batch_size=batch_size, sampler=train_sampler)\n","\n","    valid_loader = torch.utils.data.DataLoader(\n","        valid_dataset, batch_size=batch_size, sampler=valid_sampler)\n","\n","    return (train_loader, valid_loader)\n","\n","\n","def get_test_loader(data_dir,\n","                    batch_size,\n","                    shuffle=True):\n","    normalize = transforms.Normalize(\n","        mean=[0.485, 0.456, 0.406],\n","        std=[0.229, 0.224, 0.225],\n","    )\n","\n","    # define transform\n","    transform = transforms.Compose([\n","        transforms.Resize((227,227)),\n","        transforms.ToTensor(),\n","        normalize,\n","    ])\n","\n","    dataset = datasets.CIFAR10(\n","        root=data_dir, train=False,\n","        download=True, transform=transform,\n","    )\n","\n","    data_loader = torch.utils.data.DataLoader(\n","        dataset, batch_size=batch_size, shuffle=shuffle\n","    )\n","\n","    return data_loader\n","\n","\n","# CIFAR10 dataset\n","train_loader, valid_loader = get_train_valid_loader(data_dir = './data',                                      batch_size = 64,\n","                       augment = False,                             \t\t     random_seed = 1)\n","\n","test_loader = get_test_loader(data_dir = './data',\n","                              batch_size = 64)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":127,"status":"ok","timestamp":1698621289389,"user":{"displayName":"Daniel Vasiliu","userId":"13280890113502714012"},"user_tz":240},"id":"VcI2DfC2tzDP"},"outputs":[],"source":["class AlexNet(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(AlexNet, self).__init__()\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n","            nn.BatchNorm2d(96),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 3, stride = 2))\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 3, stride = 2))\n","        self.layer3 = nn.Sequential(\n","            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(384),\n","            nn.ReLU())\n","        self.layer4 = nn.Sequential(\n","            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(384),\n","            nn.ReLU())\n","        self.layer5 = nn.Sequential(\n","            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 3, stride = 2))\n","        self.fc = nn.Sequential(\n","            nn.Dropout(0.5),\n","            nn.Linear(9216, 4096),\n","            nn.ReLU())\n","        self.fc1 = nn.Sequential(\n","            nn.Dropout(0.5),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU())\n","        self.fc2= nn.Sequential(\n","            nn.Linear(4096, num_classes))\n","\n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = self.layer5(out)\n","        out = out.reshape(out.size(0), -1)\n","        out = self.fc(out)\n","        out = self.fc1(out)\n","        out = self.fc2(out)\n","        return out"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":1030,"status":"ok","timestamp":1698621293350,"user":{"displayName":"Daniel Vasiliu","userId":"13280890113502714012"},"user_tz":240},"id":"S2YvQBrmtzDQ"},"outputs":[],"source":["num_classes = 10\n","num_epochs = 20\n","batch_size = 40\n","learning_rate = 0.001\n","\n","model = AlexNet(num_classes).to(device)\n","\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","# optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","\n","# Train the model\n","total_step = len(train_loader)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2070188,"status":"ok","timestamp":1698623365435,"user":{"displayName":"Daniel Vasiliu","userId":"13280890113502714012"},"user_tz":240},"id":"x8SoFcxKtzDQ","outputId":"87ab786d-afe1-4018-b503-51dbad5cf486"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/20], Step [704/704], Loss: 2.8651\n","Accuracy of the network on the 5000 validation images: 27.7 %\n","Epoch [2/20], Step [704/704], Loss: 1.7331\n","Accuracy of the network on the 5000 validation images: 35.82 %\n","Epoch [3/20], Step [704/704], Loss: 1.9101\n","Accuracy of the network on the 5000 validation images: 39.88 %\n","Epoch [4/20], Step [704/704], Loss: 1.6825\n","Accuracy of the network on the 5000 validation images: 48.5 %\n","Epoch [5/20], Step [704/704], Loss: 1.8427\n","Accuracy of the network on the 5000 validation images: 55.9 %\n","Epoch [6/20], Step [704/704], Loss: 1.1573\n","Accuracy of the network on the 5000 validation images: 62.54 %\n","Epoch [7/20], Step [704/704], Loss: 1.3595\n","Accuracy of the network on the 5000 validation images: 67.14 %\n","Epoch [8/20], Step [704/704], Loss: 0.7868\n","Accuracy of the network on the 5000 validation images: 70.62 %\n","Epoch [9/20], Step [704/704], Loss: 0.6287\n","Accuracy of the network on the 5000 validation images: 74.36 %\n","Epoch [10/20], Step [704/704], Loss: 0.4256\n","Accuracy of the network on the 5000 validation images: 76.12 %\n","Epoch [11/20], Step [704/704], Loss: 0.9150\n","Accuracy of the network on the 5000 validation images: 76.0 %\n","Epoch [12/20], Step [704/704], Loss: 0.0277\n","Accuracy of the network on the 5000 validation images: 77.3 %\n","Epoch [13/20], Step [704/704], Loss: 1.5010\n","Accuracy of the network on the 5000 validation images: 79.52 %\n","Epoch [14/20], Step [704/704], Loss: 0.9470\n","Accuracy of the network on the 5000 validation images: 80.88 %\n","Epoch [15/20], Step [704/704], Loss: 0.3457\n","Accuracy of the network on the 5000 validation images: 80.98 %\n","Epoch [16/20], Step [704/704], Loss: 0.0610\n","Accuracy of the network on the 5000 validation images: 81.12 %\n","Epoch [17/20], Step [704/704], Loss: 0.0481\n","Accuracy of the network on the 5000 validation images: 80.82 %\n","Epoch [18/20], Step [704/704], Loss: 0.0585\n","Accuracy of the network on the 5000 validation images: 81.6 %\n","Epoch [19/20], Step [704/704], Loss: 0.2658\n","Accuracy of the network on the 5000 validation images: 81.16 %\n","Epoch [20/20], Step [704/704], Loss: 1.0069\n","Accuracy of the network on the 5000 validation images: 82.72 %\n"]}],"source":["total_step = len(train_loader)\n","\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        # Move tensors to the configured device\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n","                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n","\n","    # Validation\n","    with torch.no_grad():\n","        correct = 0\n","        total = 0\n","        for images, labels in valid_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            del images, labels, outputs\n","\n","        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total))"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21808,"status":"ok","timestamp":1698624547037,"user":{"displayName":"Daniel Vasiliu","userId":"13280890113502714012"},"user_tz":240},"id":"CknrFvNptzDR","outputId":"17b92517-5e39-428b-863c-218e70cfc388"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of the network on the 10000 test images: 81.88 %\n"]}],"source":["with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","        del images, labels, outputs\n","\n","    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))\n"]},{"cell_type":"markdown","metadata":{},"source":["\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
